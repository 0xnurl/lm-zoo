#!/usr/bin/env python3

with open("/opt/vocab.txt", "r") as f:
    vocab = set(l.strip() for l in f)

import subprocess
import sys

tokenized = subprocess.check_output(["tokenize_inner", sys.argv[1]]).decode("utf-8").strip()
for line in tokenized.strip().split("\n"):
    unks = [token if token in vocab else "<unk>" for token in line.strip(" ").split(" ")]
    print(" ".join(map(str, unks)))
