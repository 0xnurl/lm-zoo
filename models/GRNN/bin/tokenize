#!/usr/bin/env python

GRNN_ROOT = "/opt/colorlessgreenRNNs"
DATA = GRNN_ROOT + "/data/wiki"
UNK_TOKEN = "<unk>"

import subprocess
import sys
sys.path.append(GRNN_ROOT + "/src")

from language_models import dictionary_corpus


corpus = dictionary_corpus.Dictionary(DATA)

tokenized = subprocess.check_output(["tokenize_inner", sys.argv[1]]).decode("utf-8").strip()
for line in tokenized.strip().split("\n"):
  unked = [token if token in corpus.word2idx else UNK_TOKEN for token in line.strip(" ").split(" ")]
  print(" ".join(unked))
