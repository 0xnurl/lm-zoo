#!/usr/bin/env python

GRNN_ROOT = "/opt/colorlessgreenRNNs"
DATA = GRNN_ROOT + "/data/wiki"

import subprocess
import sys
sys.path.append(GRNN_ROOT + "/src")

from language_models import dictionary_corpus


corpus = dictionary_corpus.Dictionary(DATA)

tokenized = subprocess.check_output(["tokenize", sys.argv[1]]).decode("utf-8").strip()
for line in tokenized.strip().split("\n"):
    unks = [0 if token in corpus.word2idx else 1 for token in line.strip(" ").split(" ")]
    print(" ".join(map(str, unks)))
