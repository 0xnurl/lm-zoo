#!/usr/bin/env python

import codecs
from pathlib import Path
import os
import re
import sys

from nltk.tokenize import TreebankWordTokenizer
import torch


checkpoint_path = Path(os.environ["LMZOO_CHECKPOINT_PATH"])
vocab_path = checkpoint_path / Path(os.environ["LMZOO_VOCABULARY_PATH"])
with vocab_path.open("r", encoding="utf-8") as f:
    vocab = set(line.strip() for line in f)

UNK_TOKEN = "<unk>"

tokenizer = TreebankWordTokenizer()
punct_re = re.compile(r"^[-.?!,]+$")

for line in codecs.open(sys.argv[1], encoding="utf-8"):
    if not line.strip():
        print()
        continue

    toks = tokenizer.tokenize(line.strip())
    toks = [tok.lower() for tok in toks]
    toks = [tok if tok in vocab else UNK_TOKEN
            for tok in toks if not punct_re.match(tok)]
    print(" ".join(toks) + " <eos>")
